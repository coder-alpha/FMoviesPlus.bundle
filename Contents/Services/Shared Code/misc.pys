#!/usr/bin/env python
# -*- coding: utf-8 -*-

#########################################################################################################
#
# Misc scrapper
#
# Coder Alpha
# https://github.com/coder-alpha
#
#
#########################################################################################################

import re, json
import sys,urllib2,HTMLParser,urllib,urlparse
import random, time, cookielib
import base64

# import Shared Code
import jsunpack as JSUNPACK

from __builtin__ import eval

USE_RESTRICT_RAPIDVIDEO = True
RAPIDVIDEO_CAPTCHA = []
USE_RESTRICT_MP4UPLOAD = True

#-------------------------------------------------------------------------------------------------------------
# Enforce IPv4 for GetlinkAPI nks Google li
# do this once at program startup
# Reference: http://stackoverflow.com/questions/2014534/force-python-mechanize-urllib2-to-only-use-a-requests
#--------------------
import socket
origGetAddrInfo = socket.getaddrinfo

def getAddrInfoWrapper(host, port, family=0, socktype=0, proto=0, flags=0):
	return origGetAddrInfo(host, port, socket.AF_INET, socktype, proto, flags)

# #replace the original socket.getaddrinfo by our version
# socket.getaddrinfo = getAddrInfoWrapper
# socket.has_ipv6 = False
#-------------------------------------------------------------------------------------------------------------

GLOBAL_TIMEOUT_FOR_HTTP_REQUEST = 15
HTTP_GOOD_RESP_CODES = ['200','206']
	
USER_AGENT = "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:48.0) Gecko/20100101 Firefox/48.0"
IE_USER_AGENT = 'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; AS; rv:11.0) like Gecko'
FF_USER_AGENT = 'Mozilla/5.0 (Windows NT 6.3; rv:36.0) Gecko/20100101 Firefox/36.0'
OPERA_USER_AGENT = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36 OPR/34.0.2036.50'
IOS_USER_AGENT = 'Mozilla/5.0 (iPhone; CPU iPhone OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10A5376e Safari/8536.25'
ANDROID_USER_AGENT = 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'
#SMU_USER_AGENT = 'URLResolver for Kodi/%s' % (addon_version)

IP_OVERIDE = True

RE_SUB1 = Regex(r'(?m)(^[^\#])')
RE_SOURCES = Regex(r'(?m)(^.+?\d+/(\d+).+$)')

supported_hosts = ['mycloud.to','mcloud.to','rapidvideo.com','streamango.com','rapidvideo','streamango','mp4upload']

USE_POST = []
RV_COOKIES = ['__cfduid=dda567790eb0b331fd9a8191dec20619e1534810793; PHPSESSID=5v3cqu54ml4rtsdfaejo533o17']

def resolve(url, https_skip=True, test=False, strip_url=True):
	video_urlf = None
	
	if 'https:' not in url and 'http:' not in url:
		url = 'http:' + url
	ourl = url
	#Log(ourl)
	data = {'test':'test'}
	
	try:
		myParams = {}
		
		#Log(page_data_string)
		video_url_a = []
		
		if 'rapidvideo.' in ourl:
			myheaders = {}
			myheaders['User-Agent'] = agent()
			myheaders['Referer'] = ourl
			
			if len(RV_COOKIES) > 0:
				myheaders['Cookie'] = RV_COOKIES[0]
				
			myParams['headers'] = myheaders
			
			if '&q=' in ourl:
				ourl_s = ourl.split('&q=')
				ourl = ourl_s[0]
				quals = [ourl_s[1]]
			else:
				quals = ['1080p','720p','480p','360p']
				
			data = {'confirm.x':44, 'confirm.y':55, 'block':1}
			edata = urllib.urlencode(data)
			page_data_string = None
			
			use_post = False
			USE_POST.append(use_post)
			
			for qs in quals:
				try:
					cookies = None
					if use_post == True:
						page_data_string, r2, r3, cookies = request((ourl + '&q=%s') % qs, post=edata, headers=myheaders, httpsskip=True, output='extended')
					else:
						page_data_string, r2, r3, cookies = request((ourl + '&q=%s') % qs, headers=myheaders, httpsskip=True, output='extended')
						
					if 'pad.php' in page_data_string:
						use_post = not use_post
						del USE_POST[:]
						USE_POST.append(use_post)
						
						if use_post == True:
							page_data_string, r2, r3, cookies = request((ourl + '&q=%s') % qs, post=edata, headers=myheaders, httpsskip=True, output='extended')
						else:
							page_data_string, r2, r3, cookies = request((ourl + '&q=%s') % qs, headers=myheaders, httpsskip=True, output='extended')
						
					if 'captcha.php' in page_data_string:
						raise Exception('RapidVideo %s requires captcha verification' % ourl)
						
					if cookies != None and len(cookies) > 0:
						del RV_COOKIES[:]
						RV_COOKIES.append(cookies)
						
					page_data_elems = HTML.ElementFromString(page_data_string)
					try:
						video_url = page_data_elems.xpath(".//div[@id='home_video']//source/@src")[0]
					except:
						video_url = None
					try:
						res = page_data_elems.xpath(".//div[@id='home_video']//source/@data-res")[0]
						if res == '999':
							res = qs.replace('p','')
					except:
						res = qs.replace('p','')
						
					if video_url != None and res != None:
						f_i = {'file':video_url, 'label':res}
						video_url_a.append(f_i)
						if USE_RESTRICT_RAPIDVIDEO == True:
							break
				except:
					pass
			
			if len(video_url_a) > 0:
				video_urlf = video_url_a
			else:
				raise Exception('No Data found in page')
			
		elif 'streamango.' in ourl:
			myheaders = {}
			myheaders['User-Agent'] = 'Mozilla'
			myheaders['Referer'] = ourl
			myParams['headers'] = myheaders
			
			page_data_string = request(ourl, headers=myheaders, httpsskip=True)
			if 'Sorry!' not in page_data_string and 'We are unable to find the video you\'re looking for' not in page_data_string:
				video_url = decode_streamango(page_data_string)
				if video_url == None:
					raise Exception('Streamango decoding error !')
					
				if video_url[len(video_url)-1] == '@':
					video_url = video_url[:-1]
					
				try:
					v_qs = video_url.rsplit('/')
					v_qs = v_qs[1]
					v_qs = re.sub(r'[^0-9]', "", v_qs)
					v_qs = int(v_qs)
				except:
					v_qs = 720
				
				quals = [1080,720,480,360,256,128,64]
				for qs in quals:
					try:
						if v_qs == qs:
							f_i = {'file':video_url, 'label':'%s' % qs}
							video_url_a.append(f_i)
							break
						elif v_qs > qs:
							i = quals.index(qs)
							f_i = {'file':video_url, 'label':'%s' % quals[i-1]}
							video_url_a.append(f_i)
							break
					except:
						pass
				
			if len(video_url_a) > 0:
				video_urlf = video_url_a
			else:
				raise Exception('No Data found in page')
				
		elif 'mp4upload.' in ourl:
			myheaders = {}
			myheaders['User-Agent'] = agent()
			myheaders['Referer'] = ourl
			myParams['headers'] = myheaders
			
			page_data_string = request(ourl, headers=myheaders, httpsskip=True)
			if 'File Not Found' in page_data_string or 'File was deleted' in page_data_string:
				raise Exception('File not available')
			else:
				video_url, err = decode_mp4upload(page_data_string)
				if err != '':
					raise Exception(err)

				for v in video_url:
					f_i = {'file':v, 'label':'720'}
					video_url_a.append(f_i)
					if USE_RESTRICT_MP4UPLOAD == True:
						break
					
			if len(video_url_a) > 0:
				video_urlf = video_url_a
			else:
				raise Exception('No Data found in page')
			
		elif 'mycloud.' in ourl or 'mcloud.' in ourl:
			#Log('============ MyCloud URL ==================')
			myheaders = {}
			myheaders['User-Agent'] = 'Mozilla'
			myheaders['Referer'] = 'http://mcloud.to'
			myParams['headers'] = myheaders
			
			if strip_url == True and 'mycloud.' in url or 'mcloud.' in url:
				pass
			
			page_data_string = str(request(url, headers=myheaders, httpsskip=True))
			#Log(page_data_string)
			
			if 'Sorry, the page you are looking for could not be found.' not in page_data_string and 'This video is in processing' not in page_data_string and 'Weâ€™re Sorry!' not in page_data_string and page_data_string.strip() != '404':	
				json_data_str = re.findall(r'({\".*(.*m3u8|.mp4|.flv).*\"})', page_data_string)[0][0]
				json_data = json.loads(json_data_str)
				video_url = json_data['file']
				if 'https:' not in video_url and 'http:' not in video_url:
					video_url = 'http:' + video_url
				
				#Log('=======video_urls_data========')
				video_urls_data = request(video_url, headers=myheaders, httpsskip=True)
				
				if video_urls_data == None or video_urls_data == '':
					raise Exception('M3U8 URL is empty')
				#Log('video_urls_data ------------> %s' % video_urls_data)
				
				try:
					video_urls_arr = re.findall(r'(hls.*)', video_urls_data)
					#Log('video_urls_arr ------------> %s' % video_urls_arr)
					if len(video_urls_arr) == 0:
						raise
					#Log('=======video_urls_data========')
					for v in video_urls_arr:
						str_url = video_url.split('list.m3u8')[0] + v
						#str_url = video_url
						f_i = {'file':str_url, 'label':v.split('/')[1]}
						video_url_a.append(f_i)
				except:
					f_i = {'file':video_url, 'label':'720'}
					video_url_a.append(f_i)
				video_urlf = video_url_a
				Log('video_urlf ------------> %s' % video_urlf)
				
				if test == True:
					Log('*** Testing MyCloud ***')
					vurls = mycloud_streams(video_urlf[len(video_urlf)-1], https_skip, myheaders)
			
	except Exception as e:
		Log('Misc.pys > resolve > Error : %s' % e)
		pass
		
	return video_urlf, base64.b64encode(json.dumps(myParams)), True
	
#
# Ref: https://github.com/Twoure/9anime.bundle/blob/6ce7aff245ef6769f2a0a6457281d8891b8452fa/Contents/Services/URL/9anime/ServiceCode.pys#L204...L222
# Author: Twoure
#
####################################################################################################
def mycloud_streams(hls_url, https_skip, headers=None):

	vurls = list()
	hls_url = hls_url['file']
	Log.Debug('Requesting %s' % hls_url)
	
	if https_skip:
		page = request(hls_url, headers=headers, httpsskip=True)
	else:
		page = HTTP.Request(hls_url, headers=headers).content
		
	Log("MyCloud m3u8 contents")
	Log("Headers: %s" % headers)
	Log(page)
	#page = RE_SUB1.sub(hls_url.rsplit('/', 1)[0]+r'/\1', page)
	#for (u, r) in RE_SOURCES.findall(page):
	#	vurls.append({'file': u, 'label': int(r)})
		
	#return vurls
	
####################################################################################################
def error(url, https_skip):
	error = ''
	ourl = url
	
	try:
		headers = {}
		headers['User-Agent'] = 'Mozilla5'
		data = {}
		
		if 'mycloud.' in url or 'mcloud.' in url:
			headers['Referer'] = 'http://mycloud.to'
		
		#Log('misc>error : %s' % url)
		del RAPIDVIDEO_CAPTCHA[:]
		if 'rapidvideo.' in ourl and len(USE_POST) > 0 and USE_POST[0] == True:
			headers = {}
			headers['User-Agent'] = agent()
			headers['Referer'] = ourl
			if len(RV_COOKIES) > 0:
				headers['Cookie'] = RV_COOKIES[0]
				
			data = {'confirm.x':44, 'confirm.y':55, 'block':1}
			edata = urllib.urlencode(data)
			page_data_string, h, c, cookies = request(url, post=edata, headers=headers, httpsskip=True, output='extended')
			if cookies != None:
				del RV_COOKIES[:]
				RV_COOKIES.append(cookies)
		else:
			page_data_string = str(request(url, headers=headers, httpsskip=True))
			
		#Log(page_data_string)
		
		if page_data_string != None:
			if ('mycloud.' in ourl or 'mcloud.' in ourl) and 'Sorry, the page you are looking for could not be found.' in page_data_string:
				error = 'URL Error.'
			elif ('mycloud.' in ourl or 'mcloud.' in ourl) and 'This video is in processing' in page_data_string:
				error = 'Video is in processing, try again later.'
			elif ('mycloud.' in ourl or 'mcloud.' in ourl) and 'Weâ€™re Sorry!' in page_data_string or page_data_string.strip() == '404':
				error = 'Video removed or blocked.'
			elif ('streamango.' in ourl or 'fruitstreams.' in ourl or 'streamcherry.' in ourl) and ('We are unable to find the video you\'re looking for' in page_data_string or 'Sorry!' in page_data_string):
				error = 'Video removed by streamango.'
			elif ('streamango.' in ourl or 'fruitstreams.' in ourl or 'streamcherry.' in ourl) and ('The file you are looking is currently converting' in page_data_string):
				error = 'Video is processing, try again later.'
			elif ('rapidvideo.' in ourl) and "We are sorry!" in page_data_string:
				error = 'Video removed or blocked.'
			elif ('rapidvideo.' in ourl) and "<script>top.location.href = '';</script>" in page_data_string:
				error = 'No data found in page'
			elif ('rapidvideo.' in ourl) and 'captcha.php' in page_data_string:
				error = 'RapidVideo %s requires captcha verification' % url
				RAPIDVIDEO_CAPTCHA.append('')
				del RV_COOKIES[:]
			elif ('mp4upload.' in ourl) and "File Not Found" in page_data_string:
				error = 'Video Not Found'
			elif ('mp4upload.' in ourl) and "File was deleted" in page_data_string:
				error = 'Video removed or blocked.'
		else:
			error = 'Page returned None'
	except:
		error = 'Page could not be retrieved'
		
	return error
	
####################################################################################################
def decode_mp4upload(html):
	
	source = None
	err = ''
	try:
		try:
			str_pattern="(eval\(function\(p,a,c,k,e,(?:r|d).*)"
			
			js = re.compile(str_pattern).findall(html)
			if len(js) == 0:
				raise Exception('No packer js found.')
			
			js = js[0]
			if 'p,a,c,k,e,' not in js:
				raise Exception('No packer js found.')
			
			html_with_unpacked_js = JSUNPACK.unpack(js)
			if html_with_unpacked_js == None:
				raise Exception('Could not unpack js.')
				
			source = re.findall(r':\"(http.*.mp4)\"', html_with_unpacked_js)
		except Exception as e:
			err = 'Mp4Upload Error: %s' % e
			Log(err)
		if source != None and len(source) == 0:
			raise Exception('No mp4 Videos found !')
	except Exception as e:
		err = 'Mp4Upload Error: %s' % e
		
			
	return source, err

####################################################################################################
def decode_streamango(html):
	
	source = None
	
	try:
		encoded = re.search('''srces\.push\(.*src:\w+\('([^']+)',(\d+)''', html)
		if encoded:
			source = decode2(encoded.group(1), int(encoded.group(2)))
	except Exception as e:
		Log(e)
	
	return source
		
def decode2(encoded, code):
		
	vid_url = ""
	k = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/='
	k = k[::-1]

	count = 0

	for index in range(0, len(encoded) - 1):
		while count <= len(encoded) - 1:
			dec1 = k.index(encoded[count])
			count += 1
			dec2 = k.index(encoded[count])
			count += 1
			dec3 = k.index(encoded[count])
			count += 1
			dec4 = k.index(encoded[count])
			count += 1

			t1 = ((dec1 << 2) | (dec2 >> 4))
			t2 = (((dec2 & 15) << 4) | (dec3 >> 2))
			t3 = ((dec3 & 3) << 6) | dec4
			t1 = t1 ^ code

			vid_url = str(vid_url) + chr(t1)

			if dec3 != 64:
				vid_url = str(vid_url) + chr(t2)
			if dec3 != 64:
				vid_url = str(vid_url) + chr(t3)

	if 'http' not in vid_url:
		vid_url = 'https:' + vid_url
	return vid_url

def request(url, close=True, redirect=True, followredirect=False, error=False, proxy=None, post=None, headers=None, mobile=False, limit=None, referer=None, cookie=None, output='', timeout='30', httpsskip=False, use_web_proxy=False, XHR=False, IPv4=False):

# output extended = 4, response = 2, responsecodeext = 2
	
	try:
		handlers = []
		redirectURL = url
		
		if IPv4 == True:
			setIP4()
		
		if error==False and not proxy == None:
			handlers += [urllib2.ProxyHandler({'http':'%s' % (proxy)}), urllib2.HTTPHandler]
			opener = urllib2.build_opener(*handlers)
			opener = urllib2.install_opener(opener)

		if error==False and output == 'cookie2' or output == 'cookie' or output == 'extended' or not close == True:
			cookies = cookielib.LWPCookieJar()
			if httpsskip or use_web_proxy:
				handlers += [urllib2.HTTPHandler(), urllib2.HTTPCookieProcessor(cookies)]
			else:
				handlers += [urllib2.HTTPHandler(), urllib2.HTTPSHandler(), urllib2.HTTPCookieProcessor(cookies)]
			opener = urllib2.build_opener(*handlers)
			opener = urllib2.install_opener(opener)
			
		try:
			if error==False:
				if sys.version_info < (2, 7, 9): raise Exception()
				import ssl; ssl_context = ssl.create_default_context()
				ssl_context.check_hostname = False
				ssl_context.verify_mode = ssl.CERT_NONE
				handlers += [urllib2.HTTPSHandler(context=ssl_context)]
				opener = urllib2.build_opener(*handlers)
				opener = urllib2.install_opener(opener)
		except:
			pass

		try: headers.update(headers)
		except: headers = {}
		if 'User-Agent' in headers:
			pass
		elif not mobile == True:
			#headers['User-Agent'] = agent()
			#headers['User-Agent'] = Constants.USER_AGENT
			headers['User-Agent'] = randomagent()		
		else:
			headers['User-Agent'] = 'Apple-iPhone/701.341'
		if 'Referer' in headers:
			pass
		elif referer == None:
			try:
				headers['Referer'] = '%s://%s/' % (urlparse.urlparse(url).scheme, urlparse.urlparse(url).netloc)
			except:
				pass
		else:
			headers['Referer'] = referer
		if not 'Accept-Language' in headers:
			headers['Accept-Language'] = 'en-US'
		if 'X-Requested-With' in headers:
			pass
		elif XHR == True:
			headers['X-Requested-With'] = 'XMLHttpRequest'
		if 'Cookie' in headers:
			pass
		elif not cookie == None:
			headers['Cookie'] = cookie

		if error==False and redirect == False:
			class NoRedirection(urllib2.HTTPErrorProcessor):
				def http_response(self, request, response): 
					if IPv4 == True:
						setIP6()
					return response

			opener = urllib2.build_opener(NoRedirection)
			opener = urllib2.install_opener(opener)

			try: del headers['Referer']
			except: pass
			
		redirectHandler = None
		urlList = []
		if error==False and followredirect:
			class HTTPRedirectHandler(urllib2.HTTPRedirectHandler):
				def redirect_request(self, req, fp, code, msg, headers, newurl):
					newreq = urllib2.HTTPRedirectHandler.redirect_request(self,
						req, fp, code, msg, headers, newurl)
					if newreq is not None:
						self.redirections.append(newreq.get_full_url())
					if IPv4 == True:
						setIP6()
					return newreq
			
			redirectHandler = HTTPRedirectHandler()
			redirectHandler.max_redirections = 10
			redirectHandler.redirections = [url]

			opener = urllib2.build_opener(redirectHandler)
			opener = urllib2.install_opener(opener)

		request = urllib2.Request(url, data=post, headers=headers)
		#print request

		try:
			response = urllib2.urlopen(request, timeout=int(timeout))
			if followredirect:
				for redURL in redirectHandler.redirections:
					urlList.append(redURL) # make a list, might be useful
					redirectURL = redURL
					
		except urllib2.HTTPError as response:
			
			try:
				resp_code = response.code
			except:
				resp_code = None
			
			try:
				content = response.read()
			except:
				content = ''
				
			if response.code == 503:
				#Log("AAAA- CODE %s|%s " % (url, response.code))
				if 'cf-browser-verification' in content:
					print("CF-OK")

					netloc = '%s://%s' % (urlparse.urlparse(url).scheme, urlparse.urlparse(url).netloc)
					#cf = cache.get(cfcookie, 168, netloc, headers['User-Agent'], timeout)
					cfc = cfcookie()
					cf = cfc.get(netloc, headers['User-Agent'], timeout)
					
					headers['Cookie'] = cf
					request = urllib2.Request(url, data=post, headers=headers)
					response = urllib2.urlopen(request, timeout=int(timeout))
				elif error == False:
					if IPv4 == True:
						setIP6()
					return
				elif error == True:
					return '%s: %s' % (response.code, response.reason), content
			elif response.code == 307:
				#Log("AAAA- Response read: %s" % response.read(5242880))
				#Log("AAAA- Location: %s" % (response.headers['Location'].rstrip()))
				cookie = ''
				try: cookie = '; '.join(['%s=%s' % (i.name, i.value) for i in cookies])
				except: pass
				headers['Cookie'] = cookie
				request = urllib2.Request(response.headers['Location'], data=post, headers=headers)
				response = urllib2.urlopen(request, timeout=int(timeout))
				#Log("AAAA- BBBBBBB %s" %  response.code)
			elif resp_code != None:
				if IPv4 == True:
					setIP6()
				if output == 'response':
					return (resp_code, None)
				return resp_code
			elif error == False:
				#print ("Response code",response.code, response.msg,url)
				if IPv4 == True:
					setIP6()
				return
			else:
				if IPv4 == True:
					setIP6()
				return
		except Exception as e:
			Log ('Error misc.py>request : %s' % url)
			Log ('Error misc.py>request : %s' % (e.args))
			if IPv4 == True:
				setIP6()
			if output == 'response':
				return (None, None)
			return None

		if output == 'cookie':
			try: result = '; '.join(['%s=%s' % (i.name, i.value) for i in cookies])
			except: pass
			try: result = cf
			except: pass

		elif output == 'response':
			if limit == '0':
				result = (str(response.code), response.read(224 * 1024))
			elif not limit == None:
				result = (str(response.code), response.read(int(limit) * 1024))
			else:
				result = (str(response.code), response.read(5242880))
				
		elif output == 'responsecodeext':
			result = (str(response.code),redirectURL)
			
		elif output == 'responsecode':
			result = str(response.code)

		elif output == 'chunk':
			try: content = int(response.headers['Content-Length'])
			except: content = (2049 * 1024)
			#Log('CHUNK %s|%s' % (url,content))
			if content < (2048 * 1024):
				if IPv4 == True:
					setIP6()
				return
			result = response.read(16 * 1024)
			if close == True: response.close()
			if IPv4 == True:
				setIP6()
			return result

		elif output == 'extended':
			try: cookie = '; '.join(['%s=%s' % (i.name, i.value) for i in cookies])
			except: pass
			try: cookie = cf
			except: pass
			content = response.headers
			result = response.read(5242880)
			if IPv4 == True:
				setIP6()
			return (result, headers, content, cookie)

		elif output == 'geturl':
			result = response.geturl()

		elif output == 'headers':
			content = response.headers
			if IPv4 == True:
				setIP6()
			return content

		else:
			if limit == '0':
				result = response.read(224 * 1024)
			elif not limit == None:
				result = response.read(int(limit) * 1024)
			else:
				result = response.read(5242880)

		if close == True:
			response.close()

		if IPv4 == True:
			setIP6()
		return result
		
	except Exception as e:
		Log ('ERROR misc.py>request %s, %s' % (e.args,url))
		if IPv4 == True:
			setIP6()
		return
		
def agent():
	return randomagent()

def randomagent():
	BR_VERS = [
		['%s.0' % i for i in xrange(18, 43)],
		['37.0.2062.103', '37.0.2062.120', '37.0.2062.124', '38.0.2125.101', '38.0.2125.104', '38.0.2125.111', '39.0.2171.71', '39.0.2171.95', '39.0.2171.99', '40.0.2214.93', '40.0.2214.111',
		 '40.0.2214.115', '42.0.2311.90', '42.0.2311.135', '42.0.2311.152', '43.0.2357.81', '43.0.2357.124', '44.0.2403.155', '44.0.2403.157', '45.0.2454.101', '45.0.2454.85', '46.0.2490.71',
		 '46.0.2490.80', '46.0.2490.86', '47.0.2526.73', '47.0.2526.80'],
		['11.0']]
	WIN_VERS = ['Windows NT 10.0', 'Windows NT 7.0', 'Windows NT 6.3', 'Windows NT 6.2', 'Windows NT 6.1', 'Windows NT 6.0', 'Windows NT 5.1', 'Windows NT 5.0']
	FEATURES = ['; WOW64', '; Win64; IA64', '; Win64; x64', '']
	RAND_UAS = ['Mozilla/5.0 ({win_ver}{feature}; rv:{br_ver}) Gecko/20100101 Firefox/{br_ver}',
				'Mozilla/5.0 ({win_ver}{feature}) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{br_ver} Safari/537.36']
	index = random.randrange(len(RAND_UAS))
	return RAND_UAS[index].format(win_ver=random.choice(WIN_VERS), feature=random.choice(FEATURES), br_ver=random.choice(BR_VERS[index]))
		
def setIP4(setoveride=False):

	if setoveride==False and IP_OVERIDE == True:
		return
	#replace the original socket.getaddrinfo by our version
	socket.getaddrinfo = getAddrInfoWrapper
	socket.has_ipv6 = False
	
def setIP6(setoveride=False):

	if setoveride==False and IP_OVERIDE == True:
		return
	#replace the IP4 socket.getaddrinfo by original
	socket.getaddrinfo = origGetAddrInfo
	socket.has_ipv6 = True
